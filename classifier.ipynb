{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download drive file\n",
    "\n",
    "import requests\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3700516\n",
      "drwxr-xr-x 2 ec2-user ec2-user       4096 Sep 14  2017 .\n",
      "drwxr-xr-x 8 ec2-user ec2-user       4096 Dec  8 01:51 ..\n",
      "-rw-r--r-- 1 ec2-user ec2-user   40289024 Sep 13  2017 bal_train.h5\n",
      "-rw-r--r-- 1 ec2-user ec2-user   37036622 Sep 13  2017 eval.h5\n",
      "-rw-r--r-- 1 ec2-user ec2-user        644 Sep 14  2017 README\n",
      "-rw-r--r-- 1 ec2-user ec2-user        653 Sep 14  2017 README~\n",
      "-rw-r--r-- 1 ec2-user ec2-user 3711974546 Sep 13  2017 unbal_train.h5\n"
     ]
    }
   ],
   "source": [
    "# Download and unpack data\n",
    "DATA_PATH = 'packed_features/'\n",
    "\n",
    "if not os.path.exists(DATA_PATH + 'bal_train.h5'):\n",
    "    download_file_from_google_drive('0B49XSFgf-0yVQk01eG92RHg4WTA', 'packed_features.zip')\n",
    "    !unzip packed_features.zip\n",
    "\n",
    "!ls -la packed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.2578125 -0.046875   0.1484375 ... -0.984375   0.484375  -1.       ]\n",
      "  [-0.0390625 -0.1484375  0.0703125 ... -0.0390625  0.09375    0.9375   ]\n",
      "  [-0.59375    0.0546875  0.1875    ... -1.         0.9921875 -1.       ]\n",
      "  ...\n",
      "  [-0.1328125 -0.0546875 -0.1640625 ... -1.         0.9921875  0.9921875]\n",
      "  [-0.40625   -0.2421875  0.3125    ... -0.6796875  0.9921875  0.9921875]\n",
      "  [-0.484375   0.125     -0.171875  ... -0.2421875  0.65625   -1.       ]]\n",
      "\n",
      " [[-0.375      0.4140625  0.6875    ...  0.6171875 -0.0390625  0.8203125]\n",
      "  [-0.578125   0.9921875  0.3671875 ...  0.9921875  0.6015625 -0.5703125]\n",
      "  [-0.03125    0.203125   0.2890625 ... -0.46875    0.2890625 -1.       ]\n",
      "  ...\n",
      "  [-0.34375    0.21875    0.15625   ... -1.        -0.484375   0.3359375]\n",
      "  [-0.390625  -0.1484375  0.1640625 ... -0.9609375  0.703125   0.9921875]\n",
      "  [-0.4375    -0.03125    0.21875   ...  0.0625     0.4140625  0.8359375]]\n",
      "\n",
      " [[-0.1640625  0.171875  -0.3046875 ...  0.9921875  0.9921875 -0.6328125]\n",
      "  [ 0.34375    0.4296875  0.3359375 ...  0.34375    0.3515625 -1.       ]\n",
      "  [-0.1015625  0.25       0.5       ... -0.78125    0.9921875 -0.671875 ]\n",
      "  ...\n",
      "  [-0.046875   0.2265625  0.28125   ...  0.9921875  0.9609375 -1.       ]\n",
      "  [ 0.578125   0.9140625  0.515625  ... -0.5703125  0.9921875 -0.1015625]\n",
      "  [ 0.6484375  0.6875     0.4921875 ...  0.359375   0.1484375  0.46875  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.6015625 -0.5390625  0.1328125 ... -1.        -0.3125     0.8671875]\n",
      "  [-0.546875  -0.671875   0.203125  ... -0.390625  -0.75       0.9921875]\n",
      "  [-0.515625  -0.5546875  0.2734375 ... -0.7578125 -1.        -0.21875  ]\n",
      "  ...\n",
      "  [-0.453125  -0.3515625  0.2890625 ...  0.5078125 -0.4765625 -1.       ]\n",
      "  [-0.4765625 -0.7265625  0.203125  ... -0.5546875 -0.375      0.859375 ]\n",
      "  [-0.3046875 -0.7734375  0.3203125 ... -0.3203125 -0.84375    0.9921875]]\n",
      "\n",
      " [[-0.4765625  0.21875   -0.5234375 ...  0.671875  -0.046875  -0.1484375]\n",
      "  [-0.4921875  0.484375  -0.765625  ... -0.515625  -0.59375   -0.390625 ]\n",
      "  [-0.46875    0.828125  -1.        ... -0.7578125 -0.9453125 -1.       ]\n",
      "  ...\n",
      "  [-0.3046875  0.7265625 -0.8671875 ... -0.6640625 -0.6328125 -1.       ]\n",
      "  [-0.75       0.9921875 -1.        ... -0.625     -0.484375  -1.       ]\n",
      "  [-0.8046875  0.90625   -1.        ... -1.        -1.        -1.       ]]\n",
      "\n",
      " [[-0.859375   0.46875   -0.03125   ... -0.6875    -1.        -1.       ]\n",
      "  [-0.484375  -0.1484375  0.1875    ...  0.421875   0.0546875  0.3125   ]\n",
      "  [ 0.03125   -0.0078125  0.046875  ... -1.        -0.1640625 -1.       ]\n",
      "  ...\n",
      "  [-0.109375  -0.1015625 -0.2265625 ...  0.3203125 -0.6640625  0.9921875]\n",
      "  [-0.15625   -0.2578125 -0.0859375 ... -1.        -0.046875   0.9921875]\n",
      "  [-0.0234375 -0.296875   0.0234375 ... -1.         0.140625   0.9921875]]] [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Examine the data\n",
    "\n",
    "def load_data(hdf5_path):\n",
    "    with h5py.File(hdf5_path, 'r') as hf:\n",
    "        x = hf.get('x')\n",
    "        y = hf.get('y')\n",
    "        video_id_list = hf.get('video_id_list')\n",
    "        x = np.array(x)\n",
    "        y = list(y)\n",
    "        video_id_list = list(video_id_list)\n",
    "        \n",
    "    return x, y, video_id_list\n",
    "\n",
    "def uint8_to_float32(x):\n",
    "    return (np.float32(x) - 128.) / 128.\n",
    "    \n",
    "def bool_to_float32(y):\n",
    "    return np.float32(y)\n",
    "\n",
    "bal_train_path = DATA_PATH + 'bal_train.h5'\n",
    "(x, y, video_id_list) = load_data(bal_train_path)\n",
    "x = uint8_to_float32(x)  # shape: (N, 10, 128)\n",
    "y = bool_to_float32(y)   # shape: (N, 527)\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import audio classifier\n",
    "\n",
    "sys.path.append('audioset-classify')\n",
    "\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from sklearn import metrics\n",
    "import importlib\n",
    "\n",
    "from utils import utilities, data_generator\n",
    "import core\n",
    "\n",
    "try:\n",
    "    import cPickle\n",
    "except BaseException:\n",
    "    import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "# https://github.com/IBM/audioset-classification/blob/master/audioset_classify\n",
    "\n",
    "def init_layer(layer):\n",
    "    if layer.weight.ndimension() == 4:\n",
    "        (n_out, n_in, height, width) = layer.weight.size()\n",
    "        n = n_in * height * width\n",
    "    elif layer.weight.ndimension() == 2:\n",
    "        (n_out, n) = layer.weight.size()\n",
    "\n",
    "    std = math.sqrt(2. / n)\n",
    "    scale = std * math.sqrt(3.)\n",
    "    layer.weight.data.uniform_(-scale, scale)\n",
    "\n",
    "    if layer.bias is not None:\n",
    "        layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.weight.data.fill_(1.)\n",
    "\n",
    "\n",
    "class EmbeddingLayers(nn.Module):\n",
    "\n",
    "    def __init__(self, freq_bins, hidden_units, drop_rate):\n",
    "        super(EmbeddingLayers, self).__init__()\n",
    "\n",
    "        self.freq_bins = freq_bins\n",
    "        self.hidden_units = hidden_units\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=freq_bins, out_channels=hidden_units,\n",
    "            kernel_size=(1, 1), stride=(1, 1), padding=(0, 0), bias=False)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=hidden_units, out_channels=hidden_units,\n",
    "            kernel_size=(1, 1), stride=(1, 1), padding=(0, 0), bias=False)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=hidden_units, out_channels=hidden_units,\n",
    "            kernel_size=(1, 1), stride=(1, 1), padding=(0, 0), bias=False)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(freq_bins)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_units)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_units)\n",
    "        self.bn3 = nn.BatchNorm2d(hidden_units)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_layer(self.conv3)\n",
    "\n",
    "        init_bn(self.bn0)\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "        init_bn(self.bn3)\n",
    "\n",
    "    def forward(self, input, return_layers=False):\n",
    "        \"\"\"input: (samples_num, time_steps, freq_bins)\n",
    "        \"\"\"\n",
    "\n",
    "        drop_rate = self.drop_rate\n",
    "\n",
    "        # (samples_num, freq_bins, time_steps)\n",
    "        x = input.transpose(1, 2)\n",
    "\n",
    "        # Add an extra dimension for using Conv2d\n",
    "        # (samples_num, freq_bins, time_steps, 1)\n",
    "        x = x[:, :, :, None].contiguous()\n",
    "\n",
    "        a0 = self.bn0(x)\n",
    "        a1 = F.dropout(F.relu(self.bn1(self.conv1(a0))),\n",
    "                       p=drop_rate,\n",
    "                       training=self.training)\n",
    "\n",
    "        a2 = F.dropout(F.relu(self.bn2(self.conv2(a1))),\n",
    "                       p=drop_rate,\n",
    "                       training=self.training)\n",
    "\n",
    "        emb = F.dropout(F.relu(self.bn3(self.conv3(a2))),\n",
    "                        p=drop_rate,\n",
    "                        training=self.training)\n",
    "\n",
    "        if return_layers is False:\n",
    "            # (samples_num, hidden_units, time_steps, 1)\n",
    "            return emb\n",
    "\n",
    "        else:\n",
    "            return [a0, a1, a2, emb]\n",
    "\n",
    "\n",
    "class DecisionLevelAveragePooling(nn.Module):\n",
    "\n",
    "    def __init__(self, freq_bins, classes_num, hidden_units, drop_rate):\n",
    "\n",
    "        super(DecisionLevelAveragePooling, self).__init__()\n",
    "\n",
    "        self.emb = EmbeddingLayers(freq_bins, hidden_units, drop_rate)\n",
    "        self.fc_final = nn.Linear(hidden_units, classes_num)\n",
    "\n",
    "    def init_weights(self):\n",
    "\n",
    "        init_layer(self.fc_final)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"input: (samples_num, freq_bins, time_steps, 1)\n",
    "        \"\"\"\n",
    "\n",
    "        # (samples_num, hidden_units, time_steps, 1)\n",
    "        b1 = self.emb(input)\n",
    "\n",
    "        # (samples_num, time_steps, hidden_units)\n",
    "        b1 = b1[:, :, :, 0].transpose(1, 2)\n",
    "\n",
    "        b2 = F.sigmoid(self.fc_final(b1))\n",
    "\n",
    "        # (samples_num, classes_num)\n",
    "        output = torch.mean(b2, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root        : INFO     Loading data time: 0.179 s\n",
      "root        : INFO     Training data shape: (22160, 10, 128)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fd2fd77ce0a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m            \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m            cuda=cuda)\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/audioset-classify/core.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_dir, workspace, mini_data, balance_type, learning_rate, filename, model_type, model, batch_size, cuda)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Backward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "# Reload packages\n",
    "importlib.reload(core)\n",
    "\n",
    "# Args\n",
    "data_dir='packed_features'\n",
    "workspace = 'results'\n",
    "filename = 'log.txt'\n",
    "model_type = 'decision_level_average_pooling'\n",
    "balance_type = 'balance_in_batch'\n",
    "mini_data = True\n",
    "cuda = False\n",
    "\n",
    "# Logs\n",
    "sub_dir = os.path.join(filename,\n",
    "                       'balance_type={}'.format(balance_type),\n",
    "                       'model_type={}'.format(model_type))\n",
    "\n",
    "logs_dir = os.path.join(workspace, 'logs', sub_dir)\n",
    "utilities.create_folder(logs_dir)\n",
    "logging = utilities.create_logging(logs_dir, filemode='w')\n",
    "\n",
    "# Train\n",
    "freq_bins = 128\n",
    "classes_num = 527\n",
    "\n",
    "# Hyper parameters\n",
    "hidden_units = 1024\n",
    "drop_rate = 0.5\n",
    "\n",
    "# batch_size = 500 CHANGE THIS BACK!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "batch_size = 1\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "'''Global average pooling.\n",
    "\n",
    "[2] Lin, Min, et al. Qiang Chen, and Shuicheng Yan. \"Network in\n",
    "network.\" arXiv preprint arXiv:1312.4400 (2013).\n",
    "'''\n",
    "model = DecisionLevelAveragePooling(freq_bins, classes_num, hidden_units, drop_rate)\n",
    "\n",
    "core.train(data_dir='packed_features', \n",
    "           workspace=workspace,\n",
    "           mini_data=mini_data,\n",
    "           balance_type=balance_type,\n",
    "           learning_rate=learning_rate,\n",
    "           filename=filename,\n",
    "           model_type=model_type,\n",
    "           model=model,\n",
    "           batch_size=batch_size,\n",
    "           cuda=cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
